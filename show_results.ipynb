{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954bb93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset\n",
      "Light Sheet data imported!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GaussianDiffusion:\n\tsize mismatch for denoise_fn.downs.0.0.block1.block.0.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 2, 3, 3]).\n\tsize mismatch for denoise_fn.downs.0.0.res_conv.weight: copying a param with shape torch.Size([64, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 2, 1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/ipykernel_113772/2371608744.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 )\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/conditionalDDPM/models/DDPM.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ema'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1224\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GaussianDiffusion:\n\tsize mismatch for denoise_fn.downs.0.0.block1.block.0.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 2, 3, 3]).\n\tsize mismatch for denoise_fn.downs.0.0.res_conv.weight: copying a param with shape torch.Size([64, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 2, 1, 1])."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from numpy import save\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models.DDPM import Unet, GaussianDiffusion, TrainerDDPM\n",
    "from models.GBM import Unet, GBM, TrainerGBM\n",
    "\n",
    "from utils.dataset import import_dataset\n",
    "\n",
    "import argparse\n",
    "\n",
    "os.umask(0o002)\n",
    "\n",
    "# Define arguments\n",
    "\n",
    "data_name='light_sheets_seq'\n",
    "dataset_path='/nfs/conditionalDDPM/data'\n",
    "logdir='/nfs/conditionalDDPM/logs/light_sheets' \n",
    "save_sample_every=1000 \n",
    " \n",
    "mode='test' \n",
    "model_type='c' \n",
    "\n",
    "image_size=256 \n",
    "sum_from = 0\n",
    "sum_to = 50\n",
    "import_timeseries = False\n",
    "sum_every_n_steps = 5\n",
    "\n",
    "timesteps=1000 \n",
    "train_num_steps=30000 \n",
    "loss='l2' \n",
    "lr=0.00002 \n",
    "batch_size=32 \n",
    "device='cuda'\n",
    "\n",
    "gif_type = 'sampling'\n",
    "\n",
    "train_loader, valid_loader, image_size, channels, dim_mults = import_dataset(data_name, batch_size, image_size, sum_from, \n",
    "                                                                             sum_to, import_timeseries, sum_every_n_steps)\n",
    "\n",
    "# condition_dim = 2 if data_name == 'light_sheets_full' else 1\n",
    "\n",
    "# Define Model\n",
    "\n",
    "model = Unet(\n",
    "    dim = 64,\n",
    "    dim_mults = dim_mults,\n",
    "    channels = channels if model_type == 'unc' else channels+1,\n",
    "    out_dim = channels, \n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "                model,\n",
    "                image_size = image_size,\n",
    "                timesteps = timesteps,   # number of steps\n",
    "                loss_type = loss,    # L1 or L2\n",
    "                channels = channels,\n",
    "                model_type = model_type,\n",
    "                device = device\n",
    "                )\n",
    "\n",
    "trainer = TrainerDDPM( \n",
    "                diffusion_model = diffusion, \n",
    "                train_loader = train_loader, \n",
    "                valid_loader = valid_loader, \n",
    "                model_type = model_type,\n",
    "                results_folder = logdir,\n",
    "                train_batch_size = batch_size,\n",
    "                save_and_sample_every = save_sample_every,\n",
    "                train_lr = lr,\n",
    "                train_num_steps = train_num_steps,   \n",
    "                device = device\n",
    "                )\n",
    "\n",
    "trainer.load()\n",
    "model=trainer.ema_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674fdcf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Show Results DDPM as AE\"\"\"\n",
    "X,Y = next(iter(valid_loader))\n",
    "\n",
    "X,Y = X.cuda(), Y.cuda()\n",
    "model.cuda()\n",
    "\n",
    "pred_ae = model.sample(Y[:4], batch_size=4)\n",
    "\n",
    "def ae_results(X,pred):\n",
    "    _,ax = plt.subplots(1,2, figsize=(10,10))\n",
    "\n",
    "    X,pred = X[0].detach().cpu(), pred[0].detach().cpu()\n",
    "    \n",
    "    ax[0].imshow(X)\n",
    "    ax[0].set_title('Input Image')\n",
    "    ax[0].grid(False)\n",
    "    ax[1].imshow(pred)\n",
    "    ax[1].set_title('Prediction')\n",
    "    ax[1].grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "for n in range(len(X)-1):\n",
    "    ae_results(X[n],pred[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aefb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Show Results DDPM\"\"\"\n",
    "\n",
    "N = 4\n",
    "\n",
    "X,Y = next(iter(valid_loader))\n",
    "\n",
    "X,Y = X.cuda(), Y.cuda()\n",
    "model.cuda()\n",
    "\n",
    "# pred = model.sample(Y[:N], batch_size=N)\n",
    "\n",
    "def results(X,Y,pred, n, data_path = './results/light_sheets/full'):\n",
    "    _,ax = plt.subplots(1,3, figsize=(10,10))\n",
    "\n",
    "    X,Y,pred = X[0].detach().cpu(), Y[0].detach().cpu(), torch.clip(pred[0],0,None).detach().cpu()\n",
    "    \n",
    "    ax[0].imshow(X)\n",
    "    ax[0].set_title('Input Image')\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    ax[1].imshow(Y)\n",
    "    ax[1].set_title('Target')\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "    ax[2].imshow(pred)\n",
    "    ax[2].set_title('Prediction')\n",
    "    ax[2].set_xticks([])\n",
    "    ax[2].set_yticks([])\n",
    "#     plt.show()\n",
    "    \n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    \n",
    "    plt.savefig(os.path.join(data_path, f'result{n:02d}'))\n",
    "    \n",
    "for n in range(N):\n",
    "    results(X[n],Y[n],pred[n],n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
