{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/nfs/conditionalDDPM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speckles Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Show Data\"\"\"\n",
    "\n",
    "from utils.dataset import import_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(image):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "data_name='speckles'\n",
    "batch_size=32\n",
    "image_size=28\n",
    "sum_from=0\n",
    "sum_to=10\n",
    "\n",
    "train_loader, valid_loader, image_size, channels, dim_mults = import_dataset(data_name, batch_size, image_size, sum_from, sum_to)\n",
    "\n",
    "x,y = next(iter(train_loader))\n",
    "\n",
    "N = 2\n",
    "\n",
    "img,label = x[N,0],y[N,0]\n",
    "\n",
    "show_image(img)\n",
    "show_image(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Show Fourier Transform Images\"\"\"\n",
    "\n",
    "import torch\n",
    "from utils.dataset import import_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(image, title=None):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.colorbar()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "data_name='speckles'\n",
    "batch_size=32\n",
    "image_size=28\n",
    "sum_from=0\n",
    "sum_to=10\n",
    "import_timeseries=False\n",
    "\n",
    "train_loader, valid_loader, image_size, channels, dim_mults = import_dataset(data_name, batch_size, image_size, sum_from, sum_to, import_timeseries)\n",
    "\n",
    "\n",
    "x,y = next(iter(valid_loader))\n",
    "\n",
    "Ns = (1,2,3,4)\n",
    "\n",
    "\"\"\"Plot a few Re Im parts\"\"\"\n",
    "\n",
    "for N in Ns:\n",
    "\n",
    "    (img,_) = x[N,0],y[N,0] if data_name == 'speckles' else (x[N],y[N])\n",
    "\n",
    "    img_fft = torch.fft.fft2(img)\n",
    "\n",
    "    fft_real = img_fft.real\n",
    "    fft_imag = img_fft.imag\n",
    "\n",
    "    show_image(img)\n",
    "    show_image(fft_real)\n",
    "    show_image(fft_imag)\n",
    "\n",
    "\"\"\"Mixing Re and Im parts\"\"\"\n",
    "\n",
    "# For Speckles\n",
    "(img,_) = x[N,0],y[N,0] if data_name == 'speckles' else (x[N],y[N])\n",
    "(img2,_) = x[N+1,0],y[N+1,0] if data_name == 'speckles' else (x[N+1],y[N+1])\n",
    "\n",
    "img2_fft = torch.fft.fft2(img2)\n",
    "fft2_real = img2_fft.real\n",
    "fft2_imag = img2_fft.imag\n",
    "\n",
    "img_comb = img_fft.clone()\n",
    "img_comb.imag = fft2_imag\n",
    "img_rev1 = torch.fft.ifft2(img_comb)\n",
    "\n",
    "img_comb = img_fft.clone()\n",
    "img_comb.real = fft2_real\n",
    "img_rev2 = torch.fft.ifft2(img_comb)\n",
    "\n",
    "show_image(img, 'img1')\n",
    "show_image(img2, 'img2')\n",
    "show_image(img_rev1.real, 'img1 Re + img2 Im')\n",
    "show_image(img_rev2.real, 'img2 Re + img1 Im')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Show Conditional/Original/Prediction\"\"\"\n",
    "\n",
    "from utils.dataset import import_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def show_results(exp_name: str,mode: str = 'train'):\n",
    "    \n",
    "    print(f'Experiment: {exp_name}\\n')\n",
    "\n",
    "    for i, name in enumerate(['condition','original','pred']):\n",
    "        print(f'Image: 100-{mode}-{name}.png')\n",
    "        f, ax = plt.subplots(figsize=(8,8))\n",
    "        full_name = f'./logs/{exp_name}/100-{mode}-{name}.png'\n",
    "        image = np.array(Image.open(full_name))\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "exp_name = 'speckles0_010'\n",
    "mode = 'train'\n",
    "\n",
    "show_results(exp_name, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"GBM Dataset\"\"\"\n",
    "\n",
    "from utils.dataset import import_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sum_from = 8\n",
    "sum_to = 150\n",
    "\n",
    "data = import_dataset(data_name= 'speckles', batch_size= 32, image_size= 28, \n",
    "                      sum_from=sum_from, sum_to=sum_to, import_timeseries=True, sum_every_n_steps=1)\n",
    "train_loader, valid_loader, image_size, channels, dim_mults = data\n",
    "\n",
    "y,x = next(iter(valid_loader))\n",
    "\n",
    "N=2\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3)\n",
    "ax1.imshow(y[N,0])\n",
    "ax2.imshow(x[N,0])\n",
    "ax3.imshow(x[N,-1])\n",
    "print(f\"Image Shape: {y.shape} Timeseries shape: {x.shape}\")\n",
    "\n",
    "# Show Images from sum_from to sum_to\n",
    "# for i in range(1,len(x[N])):\n",
    "    \n",
    "#     fig,ax = plt.subplots(1,2, figsize=(10,20))\n",
    "    \n",
    "#     plot1 = ax[0].imshow(x[N,i])\n",
    "#     ax[0].set_title(f't={i}')\n",
    "    \n",
    "#     diff = x[N,i]-x[N,i-1]\n",
    "#     plot2 = ax[1].imshow(diff)\n",
    "#     ax[1].set_title(f't={i} - t={i-1}')\n",
    "    \n",
    "#     plt.colorbar(plot1,ax=ax[0],shrink=0.2)\n",
    "#     plt.colorbar(plot2,ax=ax[1],shrink=0.2)\n",
    "    \n",
    "# # Pixel Evolution\n",
    "# I=[]\n",
    "# plt.figure()\n",
    "# for n in range(0,len(x[N])):\n",
    "#     I.append(x[N,n,:,:].mean().item())\n",
    "# plt.scatter(np.linspace(sum_from,sum_to, sum_to-sum_from),I, label=f'x={i}, y={j}')\n",
    "\n",
    "# Pixel Evolution\n",
    "\n",
    "init_range = np.linspace(0.,1., 21)\n",
    "ranges = list(zip(init_range[0:], init_range[1:]))\n",
    "for r_in, r_out in ranges:\n",
    "    plt.figure()\n",
    "    last_values=[]\n",
    "    for i in range(0,28):\n",
    "        for j in range(0,28):\n",
    "            I=[]\n",
    "            if x[N,1,j,i] > r_in and x[N,1,j,i] < r_out:\n",
    "                for n in range(0,len(x[N])):\n",
    "                    I.append(x[N,n,j,i].item())\n",
    "#                 plt.scatter(np.linspace(sum_from,sum_to, sum_to-sum_from-1),I, label=f'x={i}, y={j}')\n",
    "                plt.scatter(np.linspace(sum_from,sum_to, sum_to-sum_from-1),I)\n",
    "                last_values.append(I[-1])\n",
    "#                 plt.legend()\n",
    "    if last_values == []:\n",
    "        last_values=[r_in,r_out]\n",
    "    plt.title(f'[{r_in:.2f},{r_out:.2f}]-->[{np.array(last_values).min():.2f}, {np.array(last_values).max():.2f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Show Images without integration in time\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "# test = np.load(os.path.join('data/speckles', f'80.0TMFPs.npz'))['arr_0']\n",
    "\n",
    "sum_from=7\n",
    "sum_to=150\n",
    "\n",
    "# # Image Evolution\n",
    "# for i in range(sum_from,sum_to):\n",
    "#     plt.figure()\n",
    "#     plt.imshow(test[0,:,:,i])\n",
    "#     plt.colorbar()\n",
    "#     plt.title('t='+str(i-sum_from))\n",
    "    \n",
    "\n",
    "# Pixel Evolution\n",
    "x,y = 14,14\n",
    "plt.figure()\n",
    "for x in range(10,18):\n",
    "    for y in range(10,18):\n",
    "        I=[]\n",
    "        for i in range(sum_from,sum_to):\n",
    "            I.append(test[0,y,x,i])\n",
    "        plt.scatter(np.linspace(sum_from,sum_to, sum_to-sum_from),I, label=f'x={x}, y={y}')\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Show Loss\"\"\"\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "exp_name = 'speckles0_500'\n",
    "exp_name = 'light_sheets2_norm_musigma'\n",
    "save_loss_every = 50\n",
    "\n",
    "data = torch.load(os.path.join('logs', exp_name, f'model.pt'))\n",
    "last_step = data['step']\n",
    "loss = data['loss']\n",
    "steps = torch.linspace(save_loss_every, last_step, int((last_step+save_loss_every)/save_loss_every))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(steps, loss)\n",
    "plt.ylim([0,0.1])\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute Entropy\"\"\"\n",
    "\n",
    "%run train.py \\\n",
    "    --dataset=speckles \\\n",
    "    --dataset_path=/nfs/conditionalDDPM/data \\\n",
    "    --logdir=/nfs/conditionalDDPM/logs/speckles0_010 \\\n",
    "    --save_sample_every=1000 \\\n",
    "    --mode=compute_entropy \\\n",
    "    --model_type=c \\\n",
    "    --image_size=28 \\\n",
    "    --sum_from=0 \\\n",
    "    --sum_to=10 \\\n",
    "    --timesteps=1000 \\\n",
    "    --train_num_steps=100000 \\\n",
    "    --loss=l2 \\\n",
    "    --lr=0.00002 \\\n",
    "    --batch_size=32 \\\n",
    "    --device=cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Make GIF\"\"\"\n",
    "\n",
    "%run train.py --dataset=speckles \\\n",
    "    --dataset_path=/nfs/conditionalDDPM/data \\\n",
    "    --logdir=/nfs/conditionalDDPM/logs/speckles0_010 \\\n",
    "    --save_sample_every=1000 \\\n",
    "    --mode=gif \\\n",
    "    --model_type=c \\\n",
    "    --image_size=28 \\\n",
    "    --sum_from=0 \\\n",
    "    --sum_to=10 \\\n",
    "    --timesteps=1000 \\\n",
    "    --train_num_steps=100000 \\\n",
    "    --loss=l2 \\\n",
    "    --lr=0.00002 \\\n",
    "    --batch_size=32 \\\n",
    "    --device=cuda\n",
    "\n",
    "%run train.py --dataset=speckles \\\n",
    "    --dataset_path=/nfs/conditionalDDPM/data \\\n",
    "    --logdir=/nfs/conditionalDDPM/logs/speckles0_050 \\\n",
    "    --save_sample_every=1000 \\\n",
    "    --mode=gif \\\n",
    "    --model_type=c \\\n",
    "    --image_size=28 \\\n",
    "    --sum_from=0 \\\n",
    "    --sum_to=50 \\\n",
    "    --timesteps=1000 \\\n",
    "    --train_num_steps=100000 \\\n",
    "    --loss=l2 \\\n",
    "    --lr=0.00002 \\\n",
    "    --batch_size=32 \\\n",
    "    --device=cuda\n",
    "\n",
    "%run train.py --dataset=speckles \\\n",
    "    --dataset_path=/nfs/conditionalDDPM/data \\\n",
    "    --logdir=/nfs/conditionalDDPM/logs/speckles0_100 \\\n",
    "    --save_sample_every=1000 \\\n",
    "    --mode=gif \\\n",
    "    --model_type=c \\\n",
    "    --image_size=28 \\\n",
    "    --sum_from=0 \\\n",
    "    --sum_to=100 \\\n",
    "    --timesteps=1000 \\\n",
    "    --train_num_steps=100000 \\\n",
    "    --loss=l2 \\\n",
    "    --lr=0.00002 \\\n",
    "    --batch_size=32 \\\n",
    "    --device=cuda\n",
    "\n",
    "%run train.py --dataset=speckles \\\n",
    "    --dataset_path=/nfs/conditionalDDPM/data \\\n",
    "    --logdir=/nfs/conditionalDDPM/logs/speckles0_500 \\\n",
    "    --save_sample_every=1000 \\\n",
    "    --mode=gif \\\n",
    "    --model_type=c \\\n",
    "    --image_size=28 \\\n",
    "    --sum_from=0 \\\n",
    "    --sum_to=500 \\\n",
    "    --timesteps=1000 \\\n",
    "    --train_num_steps=100000 \\\n",
    "    --loss=l2 \\\n",
    "    --lr=0.00002 \\\n",
    "    --batch_size=32 \\\n",
    "    --device=cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Show Lightsheets data\"\"\"\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def show_image(img, pos=[0,-1,0,-1], vmin=None, vmax=None, title=None, colorbar=True):\n",
    "    \n",
    "    if not vmin:\n",
    "        vmin=img.min()\n",
    "    if not vmin:\n",
    "        vmax=img.max()\n",
    "        \n",
    "    a,b,c,d = pos[0],pos[1],pos[2], pos[3]\n",
    "    plt.figure()\n",
    "    plt.imshow(img[a:b,c:d], vmin=vmin, vmax=vmax)\n",
    "    if colorbar:\n",
    "        plt.colorbar()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        \n",
    "def norm_maxmin(img):\n",
    "    return (img-img.min())/(img.max()-img.min())\n",
    "\n",
    "def norm_gauss(img):\n",
    "    return (img-img.mean())/(img.std())\n",
    "\n",
    "def norm_energy(img):\n",
    "    return img/img.mean()\n",
    "       \n",
    "\n",
    "data_path = './data/light_sheets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 2 --> z_shift 9 x_shift 45 energy 35.26\n",
      "Position 3 --> z_shift 13 x_shift 86 energy 32.90\n",
      "Position 4 --> z_shift 17 x_shift 126 energy 32.09\n",
      "Position 5 --> z_shift 19 x_shift 156 energy 30.43\n",
      "Position 6 --> z_shift 22 x_shift 189 energy 28.99\n",
      "Position 7 --> z_shift 26 x_shift 227 energy 27.78\n",
      "Position 8 --> z_shift 30 x_shift 265 energy 26.82\n",
      "Position 9 --> z_shift 34 x_shift 302 energy 26.19\n",
      "Position 10 --> z_shift 38 x_shift 340 energy 26.64\n",
      "Position 11 --> z_shift 42 x_shift 376 energy 25.73\n",
      "Position 12 --> z_shift 46 x_shift 416 energy 24.79\n",
      "Position 13 --> z_shift 50 x_shift 456 energy 23.61\n",
      "Position 14 --> z_shift 54 x_shift 497 energy 22.70\n",
      "Position 15 --> z_shift 58 x_shift 532 energy 22.07\n",
      "Position 16 --> z_shift 62 x_shift 569 energy 21.23\n",
      "Position 17 --> z_shift 66 x_shift 607 energy 19.87\n",
      "\n",
      "Tiling images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 70.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 1 --> Scaling factor = 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/nfs/conditionalDDPM/utils/dataset.py:345: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  ratio = diffused_img.mean()/img.mean()\n",
      "2240it [00:15, 141.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 2 --> Scaling factor = 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 3 --> Scaling factor = 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 4 --> Scaling factor = 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 5 --> Scaling factor = 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 6 --> Scaling factor = 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 7 --> Scaling factor = 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 8 --> Scaling factor = 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 9 --> Scaling factor = 9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 10 --> Scaling factor = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 11 --> Scaling factor = 11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 12 --> Scaling factor = 12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 13 --> Scaling factor = 13000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 14 --> Scaling factor = 14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 15 --> Scaling factor = 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 140.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 16 --> Scaling factor = 16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 140.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 17 --> Scaling factor = 17000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 18 --> Scaling factor = 18000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 19 --> Scaling factor = 19000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 141.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 20 --> Scaling factor = 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:15, 140.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 21 --> Scaling factor = 21000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:16, 139.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 22 --> Scaling factor = 22000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:16, 139.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 23 --> Scaling factor = 23000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:16, 139.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 24 --> Scaling factor = 24000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:16, 138.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusing Step 25 --> Scaling factor = 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:16, 139.60it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 25 is out of bounds for dimension 1 with size 25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/ipykernel_98551/1210576624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                                                              \u001b[0mseq_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                                              \u001b[0mseq_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                                                              force_download = False)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/conditionalDDPM/utils/dataset.py\u001b[0m in \u001b[0;36mimport_dataset\u001b[0;34m(data_name, batch_size, image_size, sum_from, sum_to, import_timeseries, sum_every_n_steps, seq_random, seq_full, force_download)\u001b[0m\n\u001b[1;32m     42\u001b[0m                                                                                 \u001b[0mseq_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_random\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                                                                 \u001b[0mseq_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_full\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                                                                                 force_download = force_download)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_mults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/conditionalDDPM/utils/dataset.py\u001b[0m in \u001b[0;36mimport_ls\u001b[0;34m(mode, batch_size, image_size, seq_random, seq_full, force_download)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Diffusing Step {i} --> Scaling factor = {factor}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiffusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ae'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 25 is out of bounds for dimension 1 with size 25"
     ]
    }
   ],
   "source": [
    "\"\"\"Import from dataset class\"\"\"\n",
    "\n",
    "import torch\n",
    "from utils.dataset import import_dataset\n",
    "from torchvision.transforms import GaussianBlur\n",
    "\n",
    "# name = 'light_sheets_full'\n",
    "# name = 'light_sheets_ae'\n",
    "# name = 'light_sheets_seq'\n",
    "name = 'light_sheets_DPSeqDiffuse'\n",
    "save_seq = False\n",
    "seq_random = True\n",
    "seq_full = True\n",
    "\n",
    "train_loader, valid_loader, image_size, channels, dim_mults = import_dataset(data_name=name, \n",
    "                                                                             batch_size=32, \n",
    "                                                                             image_size = 256,\n",
    "                                                                             seq_random = True,\n",
    "                                                                             seq_full = True,\n",
    "                                                                             force_download = False)\n",
    "\n",
    "x,y = next(iter(valid_loader))\n",
    "\n",
    "N = 3\n",
    "\n",
    "if name.endswith('seq') or name.endswith('dpseq'):\n",
    "    if save_seq:\n",
    "        for i in range(y.shape[2]):\n",
    "            step = y[N,0,i].clone()\n",
    "            show_image(step, vmin=0, vmax= y[N,0,0].max(), colorbar=False, title=f'seq_{i:02d}')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            data_path = './results/sequence'\n",
    "            if not os.path.exists(data_path):\n",
    "                os.makedirs(data_path)\n",
    "            plt.savefig(os.path.join(data_path,f'seq_{i:02d}.png'))\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if seq_full:\n",
    "            step = -1\n",
    "            x,y = x[N,0,0],y[N,0,step]\n",
    "        else:\n",
    "            step = None\n",
    "            x,y = x[N,0],y[N,0]\n",
    "            \n",
    "        step_name = 'Random' if not step else str(step)\n",
    "        show_image(x, title='Step 00')\n",
    "        show_image(y, title=f'Step {step_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check Histo\"\"\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from utils.dataset import import_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# name = 'light_sheets_full'\n",
    "# name = 'light_sheets_ae'\n",
    "name = 'light_sheets_seq'\n",
    "\n",
    "# train_loader, valid_loader, image_size, channels, dim_mults = import_dataset(data_name=name, \n",
    "#                                                                              batch_size=32, \n",
    "#                                                                              image_size = 128,\n",
    "#                                                                              seq_random = False,\n",
    "#                                                                              seq_full = True,\n",
    "#                                                                              force_download = False)\n",
    "\n",
    "# noisy=[]\n",
    "# for x,y in tqdm(train_loader):\n",
    "#     noisy.append(y[:,:,1:])\n",
    "\n",
    "# noisy = torch.cat(noisy)\n",
    "y.min()\n",
    "# plt.plot(torch.histc(noisy.flatten(),bins=100))\n",
    "# plt.hist(noisy.reshape(-1), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Heat equation\"\"\"\n",
    "# https://srome.github.io/Why-Blurring-an-Image-is-Similar-to-Warming-Your-Coffee/\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def update_step(img: Tensor, steps: int = 1, dt: float = 0.1):\n",
    "    assert img.ndim == 4, 'Image should be (B,C,H,W)'\n",
    "    vmax,vmin = img.max(),img.min()\n",
    "    for i in range(steps):\n",
    "        laplacian_kernel = Tensor([[0,1,0],[1.,-4,1],[0,1,0]], device=img.device)[None,None]\n",
    "        img += dt*F.conv2d(img,kernel, padding=1)\n",
    "    return img\n",
    "\n",
    "name = 'light_sheets_seq'\n",
    "# train_loader, valid_loader, image_size, channels, dim_mults = import_dataset(data_name=name, batch_size=32, image_size = 256)\n",
    "\n",
    "x,y = next(iter(valid_loader))\n",
    "N = 0\n",
    "\n",
    "step_first = y[N,0,0]\n",
    "step_last = y[N,0,-1]\n",
    "step_last_simulated = update_step(step_first[None,None].clone(), steps=1, dt=0.1)[0,0]\n",
    "\n",
    "show_image(step_first,title='First step')\n",
    "show_image(step_last,title='Last step')\n",
    "show_image(step_last_simulated,title='Last step simulated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda x: x*2, (13,13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Show image 39\"\"\"\n",
    "img = np.load(os.path.join(data_path, f'pos39_ims.npz'), allow_pickle=True)['arr_0']\n",
    "show_image(img[10], title='Image 1')\n",
    "\n",
    "\"\"\"Remark: image 39 not good\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check Clear Left/More Blur Right\"\"\"\n",
    "\n",
    "\"\"\"Show image 39\"\"\"\n",
    "img = np.load(os.path.join(data_path, f'pos1_ims.npz'), allow_pickle=True)['arr_0']\n",
    "show_image(img[1], title='Full Image')\n",
    "show_image(img[1,700:900,:200], title='Left-hand side')\n",
    "show_image(img[1,700:900,800:1000], title='Right-hand side')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Show one images\"\"\"\n",
    "img1 = np.load(os.path.join(data_path, f'pos1_ims.npz'), allow_pickle=True)['arr_0']\n",
    "img10 = np.load(os.path.join(data_path, f'pos10_ims.npz'), allow_pickle=True)['arr_0']\n",
    "img20 = np.load(os.path.join(data_path, f'pos20_ims.npz'), allow_pickle=True)['arr_0']\n",
    "img30 = np.load(os.path.join(data_path, f'pos30_ims.npz'), allow_pickle=True)['arr_0']\n",
    "img40 = np.load(os.path.join(data_path, f'pos40_ims.npz'), allow_pickle=True)['arr_0']\n",
    "\n",
    "print(\"Remark: More Blurry on the Right, More clear on the Left\")\n",
    "print(f'Image shape: {img1.shape}')\n",
    "\n",
    "show_image(img1[0], title='Image 1')\n",
    "show_image(img10[0], title='Image 10')\n",
    "show_image(img20[0], title='Image 20')\n",
    "show_image(img30[0], title='Image 30')\n",
    "show_image(img40[0], title='Image 40')\n",
    "show_image(img1[0], [600,1000,0,200], 'Left')\n",
    "show_image(img1[0], [400,800,400,600], 'Center')\n",
    "show_image(img1[0], [300,700,800,1000], 'Right')\n",
    "\n",
    "show_image(img30[0], [300,700,200,400], 'Right Shifted by 600pixels on the left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Show Stripe\"\"\"\n",
    "img45 = np.load(os.path.join(data_path, f'pos45_ims.npz'), allow_pickle=True)['arr_0']\n",
    "\n",
    "img45 = img45[:,:,:128]\n",
    "N=0\n",
    "\n",
    "show_image(img45[N], title='gt')\n",
    "for n in reversed(range(1,45)):\n",
    "    img = np.load(os.path.join(data_path, f'pos{n}_ims.npz'), allow_pickle=True)['arr_0']\n",
    "    img = img[:,:,(n*20):(128+n*20)]\n",
    "    show_image(img[N], title=f'x {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Show same image acquired N times\"\"\"\n",
    "img = np.load(os.path.join(data_path, f'pos1_ims.npz'), allow_pickle=True)['arr_0']\n",
    "for i in range(len(img)):\n",
    "    pos=[0,-1,0,-1]\n",
    "#     pos=[800,900,400,500]\n",
    "\n",
    "    show_image(img[i],pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Show positions from 1 to 45\"\n",
    "\n",
    "for i in range(1,46):\n",
    "    img = np.load(os.path.join(data_path, f'pos{i}_ims.npz'), allow_pickle=True)['arr_0']\n",
    "    \n",
    "    show_image(img[20], colorbar=False, title=f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Show Differences\"\"\"\n",
    "img = np.load(os.path.join(data_path, f'pos1_ims.npz'), allow_pickle=True)['arr_0']\n",
    "img2 = np.load(os.path.join(data_path, f'pos2_ims.npz'), allow_pickle=True)['arr_0']\n",
    "\n",
    "img = norm(img)\n",
    "img2 = norm(img2)\n",
    "\n",
    "shift = 20\n",
    "\n",
    "show_image(img[0],title='img1')\n",
    "show_image(img2[0],title='img2')\n",
    "\n",
    "for i in range(1,shift+1):\n",
    "    pos=[0,-1,0,-1]\n",
    "#     pos=[800,900,400,500]\n",
    "    diff = img[0,:,i:]-img2[0,:,:-i]\n",
    "    show_image(diff, pos, f'shift={i} Mean = {diff.mean():.4f}')\n",
    "#     show_image(img[i]-img2[i],pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check 20 pixels shifts\"\"\"\n",
    "\n",
    "for i in range(2,54):\n",
    "    img = np.load(os.path.join(data_path, f'pos{i}_ims.npz'), allow_pickle=True)['arr_0']\n",
    "    \n",
    "    show_image(img[0, :128, 896-(i-1)*20:-(i-1)*20], title=f'Image {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot intensity along rows\"\"\"\n",
    "img = np.load(os.path.join(data_path, f'pos1_ims.npz'), allow_pickle=True)['arr_0']\n",
    "\n",
    "for i in range(1000):\n",
    "    plt.figure()\n",
    "    plt.plot(img[0, i])\n",
    "    plt.title(f'row {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Patch in tiles\"\"\"\n",
    "import torch\n",
    "            \n",
    "def patch(img):\n",
    "    \"\"\"Patch a batch of images in tiles (size,stride)\"\"\"\n",
    "    b,h,w = img.shape\n",
    "    size = 128 # patch size\n",
    "    stride = 128 # patch stride\n",
    "    return (img.unfold(1, size, stride).unfold(2, size, stride)).reshape(b,-1,size,stride)\n",
    "\n",
    "def unpatch(patches):\n",
    "    \"\"\"Patch a batch of images in tiles (size,stride)\"\"\"\n",
    "    b,p,h,w = patches.shape\n",
    "    size = 128 # patch size\n",
    "    stride = 128 # patch stride\n",
    "    return (img.unfold(1, size, stride).unfold(2, size, stride)).reshape(b,-1,size,stride)\n",
    "\n",
    "img = np.load(os.path.join(data_path, f'pos1_ims.npz'), allow_pickle=True)['arr_0']\n",
    "img = torch.tensor(img)\n",
    "\n",
    "img = img[:,:,20:]\n",
    "\n",
    "patches = patch(img)\n",
    "\n",
    "show_image(img[0,128:256,:128])\n",
    "show_image(patches[0,8])\n",
    "diff = patches[0,0] - img[0,:128,:128]\n",
    "show_image(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from math import exp\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "ssim_loss = SSIM()\n",
    "\n",
    "# img1 = Tensor(tiff.imread(f'./data/light_sheets/Pos{1:02d}/img_channel000_position{1:03d}_time000000000_z{4:03d}.tif').astype(np.int32))\n",
    "\n",
    "# metrics=[]\n",
    "# for i in range(101):\n",
    "#     img = Tensor(tiff.imread(f'./data/light_sheets/Pos{11:02d}/img_channel000_position{11:03d}_time000000000_z{i:03d}.tif').astype(np.int32))\n",
    "# #     diff.append(((img1[a:b,c+10*shift:d]-img[a:b,c:d-10*shift])**2).mean())\n",
    "#     img_ref = img1[a:b,c+10*shift:d][None,None]\n",
    "#     img_test = img[a:b,c:d-10*shift][None,None]\n",
    "    \n",
    "#     metrics.append(ssim_loss(img_ref,img_test))\n",
    "# metrics.index(max(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Found coincidence!!!!!!!!!!\"\"\"\n",
    "\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a,b,c,d=0,400,400,-1\n",
    "\n",
    "shift = 40\n",
    "pos_diff = 2\n",
    "img1 = Tensor(tiff.imread(f'./data/light_sheets/Pos{1:02d}/img_channel000_position{1:03d}_time000000000_z{4:03d}.tif').astype(np.int32))\n",
    "show_image(img1[a:b,c+pos_diff*shift:d], colorbar=False)\n",
    "# img2 = Tensor(tiff.imread(f'./data/light_sheets/Pos{2:02d}/img_channel000_position{2:03d}_time000000000_z{10:03d}.tif').astype(np.int32))\n",
    "# shift = 44\n",
    "# show_image(img2[a:b,c:d-pos_diff*shift], title=str(i), colorbar=False)\n",
    "    \n",
    "# for i in range(10,20):\n",
    "#     img3 = Tensor(tiff.imread(f'./data/light_sheets/Pos{3:02d}/img_channel000_position{3:03d}_time000000000_z{i:03d}.tif').astype(np.int32))\n",
    "#     show_image(img3[a:b,c:d-pos_diff*shift], title=str(i), colorbar=False)\n",
    "\n",
    "for i in range(38,42):\n",
    "    for shift in range(38,42):\n",
    "        img3 = Tensor(tiff.imread(f'./data/light_sheets/Pos{11:02d}/img_channel000_position{11:03d}_time000000000_z{i:03d}.tif').astype(np.int32))\n",
    "        show_image(img1[a:b,c+pos_diff*shift:d] - img3[a:b,c:d-pos_diff*shift], title=f'z_stack {i} shift {shift}', colorbar=True)\n",
    "\n",
    "\n",
    "# img11 = Tensor(tiff.imread(f'./data/light_sheets/Pos{11:02d}/img_channel000_position{11:03d}_time000000000_z{40:03d}.tif').astype(np.int32))\n",
    "# shift=38\n",
    "# show_image(img2[a:b,c:d-10*shift], colorbar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check for the whole z-stack\"\"\"\n",
    "\n",
    "z_shift=4\n",
    "positions =   [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15]\n",
    "shifts =      [40, 0,40,40,40,40,40,40,40,40,40,38,40,40,40,40]\n",
    "z_shifts =    [ 0, 4,10,16,16,20,24,28,32,36,40,40,44,48,52,56]\n",
    "i=0\n",
    "img_ref = Tensor(tiff.imread(f'./data/light_sheets/Pos{1:02d}/img_channel000_position{1:03d}_time000000000_z{4:03d}.tif').astype(np.int32))\n",
    "while i*z_shift < 101 and i < positions[-1]:\n",
    "    img = Tensor(tiff.imread(f'./data/light_sheets/Pos{i:02d}/img_channel000_position{i:03d}_time000000000_z{z_shifts[i]:03d}.tif').astype(np.int32))\n",
    "    img = img[:400,:-i*shifts[i]] if i>1 else img[:400]\n",
    "    \n",
    "    fig, (ax0,ax1,ax2) = plt.subplots(1,3, figsize=(20,20))\n",
    "    ax0.imshow(img_ref[:400,i*shifts[i]:])\n",
    "    ax0.set_title(f'Pos{1:02d}, z{4:03d}')\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title(f'Pos{i:02d}, z{z_shifts[i]:03d}')\n",
    "    ax2.imshow(img_ref[:400,i*shifts[i]:]-img)\n",
    "    ax2.set_title(f'Difference')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Open metadata as json\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Widgets\"\"\"\n",
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display\n",
    "\n",
    "# image1 = [Tensor(tiff.imread(f'./data/light_sheets/Pos{6:02d}/img_channel000_position{6:03d}_time000000000_z{i:03d}.tif').astype(np.int32)) for i in range(101)]\n",
    "\n",
    "# def show(n):\n",
    "#     show_image(image1[n])\n",
    "    \n",
    "# widgets.interact(show, n=range(101))\n",
    "\n",
    "# def f(x):\n",
    "#     return x\n",
    "\n",
    "# out = widgets.interact(f, x=10)\n",
    "# display(out)\n",
    "# widgets.Dropdown(\n",
    "#     options=['1', '2', '3'],\n",
    "#     value='2',\n",
    "#     description='Number:',\n",
    "#     disabled=False,\n",
    "# )\n",
    "\n",
    "# !jupyter nbextension install --user --py widgetsnbextension\n",
    "# !jupyter nbextension enable --user --py widgetsnbextension\n",
    "# !jupyter lab clean\n",
    "# !jupyter lab build\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Compute Frechet Inception Distance\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def calculate_fid(act1, act2):\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid\n",
    "\n",
    "img = np.load(os.path.join(data_path, f'pos45_ims.npz'), allow_pickle=True)['arr_0']\n",
    "\n",
    "_,h,w = img.shape\n",
    "\n",
    "img_left1 = img[0,600:728,:128]\n",
    "img_left2 = img[0,728:856,:128]\n",
    "img_right1 = img[0,600:728,w-128:]\n",
    "img_right2 = img[0,728:856,w-128:]\n",
    "\n",
    "\n",
    "show_image(img_left1, title='Left 1')\n",
    "show_image(img_left2, title='Left 2')\n",
    "show_image(img_right1, title='Right 1')\n",
    "show_image(img_right2, title='Right 2')\n",
    "\n",
    "print(\"Between two regions on the left-hand side, FID:\", calculate_fid(img_left1, img_left2))\n",
    "print(\"Between two regions on the right-hand side, FID:\", calculate_fid(img_right1, img_right2))\n",
    "print(\"Between one region in the left-hand side and one in the right-hand side, FID\", calculate_fid(img_left1, img_right1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Detect Blur in an image\"\"\"\n",
    "import torch\n",
    "\n",
    "img = np.load(os.path.join(data_path, f'pos1_ims.npz'), allow_pickle=True)['arr_0']\n",
    "img = torch.tensor(img)\n",
    "\n",
    "def laplacian(xs, f, create_graph=False, keep_graph=None, return_grad=False):\n",
    "    xis = [xi.requires_grad_() for xi in xs.flatten(start_dim=1).t()]\n",
    "    xs_flat = torch.stack(xis, dim=1)\n",
    "    ys = f(xs_flat.view_as(xs))\n",
    "    (ys_g, *other) = ys if isinstance(ys, tuple) else (ys, ())\n",
    "    ones = torch.ones_like(ys_g)\n",
    "    (dy_dxs,) = torch.autograd.grad(ys_g, xs_flat, ones, create_graph=True)\n",
    "    lap_ys = sum(\n",
    "        torch.autograd.grad(\n",
    "            dy_dxi, xi, ones, retain_graph=True, create_graph=create_graph\n",
    "        )[0]\n",
    "        for xi, dy_dxi in zip(xis, (dy_dxs[..., i] for i in range(len(xis))))\n",
    "    )\n",
    "    if not (create_graph if keep_graph is None else keep_graph):\n",
    "        ys = (ys_g.detach(), *other) if isinstance(ys, tuple) else ys.detach()\n",
    "    result = lap_ys, ys\n",
    "    if return_grad:\n",
    "        result += (dy_dxs.detach().view_as(xs),)\n",
    "    return result\n",
    "\n",
    "laplacian(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import grad\n",
    "\n",
    "img = np.load(os.path.join(data_path, f'pos1_ims.npz'), allow_pickle=True)['arr_0']\n",
    "img = torch.tensor(img, dtype=torch.double)\n",
    "\n",
    "def nth_derivative(f, wrt, n):\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        grads = grad(f, wrt, create_graph=True)[0]\n",
    "        f = grads.sum()\n",
    "\n",
    "    return grads\n",
    "\n",
    "x = torch.arange(4, requires_grad=True).reshape(2, 2)\n",
    "loss = (x ** 4).sum()\n",
    "\n",
    "print(nth_derivative(f=loss, wrt=x, n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "img = np.load(os.path.join(data_path, f'pos1_ims.npz'), allow_pickle=True)['arr_0']\n",
    "img = torch.tensor(img, dtype=torch.double)[:,None]\n",
    "img = norm(img)\n",
    "\n",
    "Gx = torch.tensor([[-1,0,1],[-2,0,2],[-1,0,1]], dtype=torch.double)[None,None]\n",
    "Gy = torch.tensor([[1,2,1],[0,0,0],[-1,-2,-1]], dtype=torch.double)[None,None]\n",
    "\n",
    "G = torch.sqrt(Gx*Gx + Gy*Gy)\n",
    "gradx = F.conv2d(img, Gx) \n",
    "grady = F.conv2d(img, Gy) \n",
    "\n",
    "grad = torch.sqrt(gradx**2 + grady**2)\n",
    "\n",
    "show_image(gradx[0,0],[400,600,400,600])\n",
    "show_image(grady[0,0],[400,600,400,600])\n",
    "show_image(grad[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Try BM3D\"\"\"\n",
    "\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "\n",
    "image_noisy = tiff.imread(f'./data/light_sheets/Pos{1:02d}/img_channel000_position{1:03d}_time000000000_z{4:03d}.tif').astype(np.int32)\n",
    "\n",
    "denoised_image = bm3d(image_noisy, sigma_psd=30/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import skimage.data\n",
    "\n",
    "# import pybm3d\n",
    "\n",
    "\n",
    "# noise_std_dev = 40\n",
    "# img = skimage.data.astronaut()\n",
    "# noise = np.random.normal(scale=noise_std_dev,\n",
    "#                          size=img.shape).astype(img.dtype)\n",
    "\n",
    "# noisy_img = img + noise\n",
    "\n",
    "# out = pybm3d.bm3d.bm3d(noisy_img, noise_std_dev)\n",
    "\n",
    "\n",
    "# print(\"PSNR of noisy image: \", noise_psnr)\n",
    "# print(\"PSNR of reconstructed image: \", out_psnr)\n",
    "\n",
    "!pip install pybm3d"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f6af117613f0bc99c2c83da1fbcb6547751a5aa2ab3fd455d2d6379b5a5d857"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
